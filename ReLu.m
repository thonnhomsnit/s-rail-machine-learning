function [Y,Xf,Af] = ReLu(x,~,~) %%%%%%%%%%%%%%%%%%%%%%%%%% change capital X to x, not original code %%%%%%%%%%%%
%RELU neural network simulation function.
%
% Auto-generated by MATLAB, 20-Sep-2022 15:27:52.
% 
% [Y] = ReLu(X,~,~) takes these arguments:
% 
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 4xQ matrix, input #1 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 2xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Layer 1
b1 = [0.13805120223283184888;0.21873349960497381894;0.030694976393707877615;-0.35612764435569504995;-0.95782465756875256879;0.75649256579199541939;-0.98426475640934008027;-0.65999950165297671667;0.15213332928869977012;-0.77663898486566773638;-0.37176938075643339854;-0.17436286803857650729;0.87389542303763245723;0.010756426513696008829;0.068065273363054595857;-0.26856603033660592095;0.84929076178618057025;0.21849412867020329143;0.0078069112379412150537;1.1133332991513771315;-0.79497006701469719037;0.86179208964210185506;-0.43045669087806670561;0.76323779906176947296];
IW1_1 = [0.060881779475826992842 0.067360162059148492864 -0.21087742480927210154 -0.95239625966421070924;-1.1609758587021288267 0.42344486127237707107 0.057876977002468396605 -0.031628814626169135527;0.059392736651367974976 0.39451652265403730491 -1.43637165421363866 0.97213940182552827096;-0.55141835259437899097 -0.097223924833699210124 0.91881266064234290436 0.024778226507751376084;-0.14382272134015106069 0.38718071877303161799 -0.88450128247789727709 0.33994788802852604626;-0.1104070312560988254 -0.66905235986023359196 0.18407979358975556927 0.22809175576486148684;-0.42486327222069797394 -0.49317815468127013112 0.21469650397470996239 0.14933085080932539945;-0.64984372894660191733 -0.26974418880003725452 -0.17041923799313335453 0.63460872853310446029;0.47206690247818294814 -0.1133766239271482984 -0.11000483249264569885 0.57237274367321644419;0.48126701413889089176 0.18134079408882092244 0.044831938917105851328 -0.62208724192331565916;0.58625415663777868946 0.045810931235638258086 0.47747371461504706236 1.1965049770482547586;0.047112175909353230796 0.52009885286215973288 -0.089976524038102578817 0.16137450165713546069;-0.38994231053039030144 -0.28274534158013975293 0.1715549308474448309 -0.8234413843559104107;0.98631957036770057101 -0.45248255372807844044 0.15114183796256486225 -0.66080043372929686551;-0.036648489025336045133 0.095261145016327902768 -0.043232158716920016106 -0.033700023630773991157;-0.40883297537686114076 -0.15761207278251970765 0.57594031604231687993 1.6391017104928355952;1.0236479180093445152 -0.42914473593217367098 -0.81495633726545069209 -1.0289811700708964004;0.32172606481917026544 -0.15827552328636057544 -0.55657209630004411682 0.3911593115421002631;-0.48557112550408010332 0.33408993998577835027 1.7865709179484332569 -0.9016799359078562226;-0.37462869640303991803 0.22268840425181390952 0.1092109848076235068 0.94974997168559616156;0.2332788480151913868 0.14832656657653378596 0.82294030944597384991 -0.090948658158553449815;-0.88236834258506158246 -1.7462663804972677895 -0.84433722918010434277 -0.0015018501391552063415;-0.40526556885982256695 0.0018383893733362466349 -0.27926542335693094188 0.064349309975145541074;-1.6002798800606117258 -1.5570838706279215291 -0.76867689613461409603 0.0057700678983970375702];

% Layer 2
b2 = [-0.24023516215695972509;0.010646935701145027187];
LW2_1 = [0.30831143743026906412 0.49393350097886401517 0.0013756578790939946125 0.04417914152735047395 -0.3287290110225524753 -0.17065788466489156816 0.91388323654382586092 -0.30114460251315300354 -0.40196112044225451587 0.49553646381304017332 -0.08203454657085959556 -0.17314157526572551693 0.042875045977476163028 0.065684477224745088653 -0.21956709552138009567 -0.13189395898401073959 0.0018048827992432469464 -7.2777840973278751756e-05 -0.023436618410633606319 0.65399670944628918168 0.054305103341650638737 1.9153598887400606898 -0.86370335319128677121 -2.1349887830702742875;0.082140708463135730932 0.091980523195824157034 -0.16559800824164408461 1.1086136473683541048 -0.60476192688900409777 0.50974683152197419744 -0.28135928511842456246 1.1044262198233709693 0.20989348901343199416 -0.6312882048833973192 -0.096800795112724352665 -0.20159679178966150026 -1.2105639201699855967 0.27899315552125303341 -0.6811839597519903089 -0.91746782340535726341 -0.2605309170244431427 -0.30929795990275588125 -0.29960034595790724365 0.84374174200502127796 0.36398262335067166351 0.025297141592027162088 -0.97703918556039459631 0.011899758125410924564];

% ===== SIMULATION ========
%%%%%%%%%%%%%%%%%%%%%%%%%% transpose output, not original code %%%%%%%%%%%%
X=x';
%%%%%%%%%%%%%%%%%%%%%%%%%% transpose output, not original code %%%%%%%%%%%%
% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
  X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
  Q = size(X{1},2); % samples/series
else
  Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    % no processing
    
    % Layer 1
    a1 = poslin_apply(repmat(b1,1,Q) + IW1_1*X{1,ts});
    
    % Layer 2
    a2 = repmat(b2,1,Q) + LW2_1*a1;
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
  Y = cell2mat(Y);
end
%%%%%%%%%%%%%%%%%%%%%%%%%% transpose output, not original code %%%%%%%%%%%%
Y(1,:)= ((Y(1,:))*(169.8391-65.2277))+65.2277; %IPF
Y(2,:)= ((Y(2,:))*(2217.028-729.5885))+729.5885; %SEA
Y=-1.*Y'; %%%% times -1 due to the minimizing ObjFn %%%%%
Y(:,1)=-1.*Y(:,1);
%%%%%%%%%%%%%%%%%%%%%%%%%% transpose output, not original code %%%%%%%%%%%%
end

% ===== MODULE FUNCTIONS ========

% Linear Positive Transfer Function
function a = poslin_apply(n,~)
  a = max(0,n);
  a(isnan(n)) = nan;
end